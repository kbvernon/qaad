<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Lecture 02: Models and Probability</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <script src="libs/fabric/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <link href="libs/animate.css/animate.xaringan.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/shareon/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain/shareagain.js"></script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="custom_style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Lecture 02: Models and Probability
### Last updated: 2022-01-15

---






## &amp;#x1F4CB; Lecture Outline

- &amp;#x1F9EA; A simple experiment
- Some terminology
- &amp;#x1F3B0; Random variables
- &amp;#x1F3B2; Probability
- &amp;#x1F4CA; Probability Distribution
- Probability Distribution as a Model
- Probability Distribution as a Function
- Probability Mass Functions
- Probability Density Functions
- &amp;#x1F697; Cars Model
- Brief Review
- A Simple Formula



---

## &amp;#x1F9EA; A simple experiment

.pull-left[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-3-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

.pull-right[

We take ten cars, send each down a track, have them brake at the same point, and measure the distance it takes them to stop.  

]



---
count: false

## &amp;#x1F9EA; A simple experiment

.pull-left[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-4-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

.pull-right[

We take ten cars, send each down a track, have them brake at the same point, and measure the distance it takes them to stop.  

__Question:__ how far do you think it will take the next car to stop?

]



---
count: false

## &amp;#x1F9EA; A simple experiment

.pull-left[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-5-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

.pull-right[

We take ten cars, send each down a track, have them brake at the same point, and measure the distance it takes them to stop.  

__Question:__ what is the __probability__ that it takes the next car more than 10 meters to stop? Less than 10? Between 10 and 15?

]



---
count: false

## &amp;#x1F9EA; A simple experiment

.pull-left[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-6-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

.pull-right[

We take ten cars, send each down a track, have them brake at the same point, and measure the distance it takes them to stop.  

__Question:__ what is the __probability__ that it takes the next car more than 10 meters to stop? Less than 10? Between 10 and 15?

Our answer to the original question should be: whatever distance is the more probable outcome.

]


---
count: false

## &amp;#x1F9EA; A simple experiment

.pull-left[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-7-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

.pull-right[

We take ten cars, send each down a track, have them brake at the same point, and measure the distance it takes them to stop.  

__Question:__ what is the __probability__ that it takes the next car more than 10 meters to stop? Less than 10? Between 10 and 15?

Our answer to the original question should be: whatever distance is the more probable outcome.

But, how do we determine this?

]



---

## Some terminology

&lt;img src="images/random_variable-coins.png" width="1207" style="display: block; margin: auto;" /&gt;



---
count: false

## Some terminology

&lt;img src="images/random_variable-outcome.png" width="1207" style="display: block; margin: auto;" /&gt;



---
count: false

## Some terminology

&lt;img src="images/random_variable-space.png" width="1207" style="display: block; margin: auto;" /&gt;



---
count: false

## Some terminology

&lt;img src="images/random_variable-variable.png" width="1207" style="display: block; margin: auto;" /&gt;



---

## &amp;#x1F3B0; Random Variables

Two types of random variable:

--

1. __Discrete__ random variables often take only _integer_ (non-decimal) values.
    - Examples: number of heads in 10 tosses of a fair coin, number of victims of the Thanos snap, number of projectile points in a stratigraphic level, number of archaeological sites in a watershed.
--
2. __Continuous__ random variables take _real_ (decimal) values.
    - Examples: cost in property damage of a superhero fight, kilocalories per kilogram, kilocalories per hour, ratio of isotopes
    - Note: for continuous random variables, the sample space is infinite!


---

## &amp;#x1F3B2; Probability

Question: Let `\(X\)` be the number of heads in two tosses of a fair coin. What is the probability that `\(X=1\)`? 

--

.pull-left[

&lt;img src="images/probability-distribution-01.png" width="80%" style="display: block; margin: auto;" /&gt;

]



---

## &amp;#x1F4CA; Probability Distribution

Question: Let `\(X\)` be the number of heads in two tosses of a fair coin. What is the probability of each outcome?

.pull-left[

&lt;img src="images/probability-distribution-02.png" width="80%" style="display: block; margin: auto;" /&gt;

]





---
count: false

## &amp;#x1F4CA; Probability Distribution

Question: Let `\(X\)` be the number of heads in two tosses of a fair coin. What is the probability of each outcome?

.pull-left[

&lt;img src="images/probability-distribution-02.png" width="80%" style="display: block; margin: auto;" /&gt;

]

.pull-right[

Probability Axioms (Kolmogorov 1956):

- __Non-negativity__: all probabilities are greater than or equal to zero.  
`$$P(X=2) \geq 0$$`  
- __Additivity__: the probability of two mutually exclusive events is the sum of their individual probabilities.  
`$$P(X=2) + P(X=1) = 3/4$$`
- __Unity__: all probabilities must sum to one.  
`$$P(X=2) + P(X=1) + P(X=0) = 1$$`  

]






---
count: false

## &amp;#x1F4CA; Probability Distribution

Question: Let `\(X\)` be the number of heads in two tosses of a fair coin. What is the probability of each outcome?

.pull-left[

&lt;img src="images/probability-distribution-02.png" width="80%" style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-16-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---

## Probability Distribution as a Model

This probability distribution is actually a probability model. 

.pull-left[

&lt;br&gt;

We can use it to form an expectation about the number of heads that will arise if we flip two coins.

This should clue you into how we will predict the car's stopping distance! 

But, first, let's unpack these probability distributions a little more.

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-17-1.png" width="504" style="display: block; margin: auto;" /&gt;


]


---

## Probability Distribution as a Model

Has two components:

.pull-left.moon-gray[

__Central-tendency__:

- Called the "first moment."
- Population mean (\\(\mu\\))
    - Gives the expected value of an experiment, `\(E[X] = \mu\)`.
- Sample mean (\\(\bar{x}\\))
    - Estimate of `\(\mu\)` based on a sample from `\(X\)` of size `\(n\)`.
    - Expected to approximate `\(\mu\)` as `\(n\)` increases.

]

.pull-right.moon-gray[

__Dispersion__:

- Called the "second moment." 
- Population variance (\\(\sigma^2\\)).
    - The expected value of the squared difference from the mean.
- Sample variance (\\(s^2\\)).
    - Estimate of `\(\sigma^2\)` based on a sample from `\(X\)` of size `\(n\)`.
- Standard deviation (\\(\sigma\\) or \\(s\\)) is the square root of the variance.

]



---
count: false

## Probability Distribution as a Model

Has two components:

.pull-left[

__Central-tendency__:

- Called the "first moment."
- Population mean (\\(\mu\\))
    - Gives the expected value of an experiment, `\(E[X] = \mu\)`.
- Sample mean (\\(\bar{x}\\))
    - Estimate of `\(\mu\)` based on a sample from `\(X\)` of size `\(n\)`.
    - Expected to approximate `\(\mu\)` as `\(n\)` increases.

]

.pull-right.moon-gray[

__Dispersion__:

- Called the "second moment." 
- Population variance (\\(\sigma^2\\)).
    - The expected value of the squared difference from the mean.
- Sample variance (\\(s^2\\)).
    - Estimate of `\(\sigma^2\)` based on a sample from `\(X\)` of size `\(n\)`.
- Standard deviation (\\(\sigma\\) or \\(s\\)) is the square root of the variance.

]



---
count: false

## Probability Distribution as a Model

Has two components:

.pull-left.moon-gray[

__Central-tendency__:

- Called the "first moment."
- Population mean (\\(\mu\\))
    - Gives the expected value of an experiment, `\(E[X] = \mu\)`.
- Sample mean (\\(\bar{x}\\))
    - Estimate of `\(\mu\)` based on a sample from `\(X\)` of size `\(n\)`.
    - Expected to approximate `\(\mu\)` as `\(n\)` increases.

]

.pull-right[

__Dispersion__:

- Called the "second moment." 
- Population variance (\\(\sigma^2\\)).
    - The expected value of the squared difference from the mean.
- Sample variance (\\(s^2\\)).
    - Estimate of `\(\sigma^2\)` based on a sample from `\(X\)` of size `\(n\)`.
- Standard deviation (\\(\sigma\\) or \\(s\\)) is the square root of the variance.

]



---
class: highlight-last-item

## Probability Distribution as a Function

These can be defined using precise mathematical functions:  

--
- A probability __mass__ function (PMF) for discrete random variables.
    - Examples: Bernoulli, Binomial, Negative Binomial, Poisson
    - Straightforward probability interpretation: \\(P(X=x) = f(x)\\).
--
- A probability __density__ function (PDF) for continuous random variables.
    - Examples: Normal, Chi-squared, Student's t, and F
    - Harder to interpret probability: 
        - What is the probability that a car takes 10.317 m to stop? 
        - What about 10.31742 m?
    - Better to consider probability above or below a value, \\(P(X &lt; x)\\), or in an interval \\(P(x_1 \leq X \leq x_2)\\).
    - Requires that the function integrate to one (probability is the area under the curve)
--
- A uniform distribution can be discrete or continuous.



---

## Probability Mass Functions

.pull-left[

&lt;br&gt;

__Bernoulli distribution__: distribution of a binary random variable (known as a "Bernoulli trial") with two possible values, 1 (success) and 0 (failure), with `\(p\)` being the probability of success. E.g., a single coin flip.

`$$f(x,p) = p^{x}(1-p)^{1-x}$$`

Mean: `\(p\)`  
Variance: `\(p(1-p)\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-18-1.png" width="504" style="display: block; margin: auto;" /&gt;

]


---

## Probability Mass Functions

.pull-left[

&lt;br&gt;

__Binomial distribution__: distribution of a random variable whose value is equal to the number of successes in `\(n\)` independent Bernoulli trials. E.g., number of heads in ten coin flips.

`$$f(x,p,n) = \binom{n}{x}p^{x}(1-p)^{1-x}$$`

Mean: `\(np\)`  
Variance: `\(np(1-p)\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-19-1.png" width="504" style="display: block; margin: auto;" /&gt;

]


---
count: false

## Probability Mass Functions

.pull-left[

&lt;br&gt;

__Binomial distribution__: distribution of a random variable whose value is equal to the number of successes in `\(n\)` independent Bernoulli trials. E.g., number of heads in ten coin flips.

`$$f(x,p,n) = \binom{n}{x}p^{x}(1-p)^{1-x}$$`

Mean: `\(np\)`  
Variance: `\(np(1-p)\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-20-1.png" width="504" style="display: block; margin: auto;" /&gt;

]


---

## Probability Mass Functions

.pull-left[

&lt;br&gt;

__Poisson distribution__: distribution of a random variable whose value is equal to the number of events occurring in a fixed interval of time or space. E.g., number of orcs passing through the Black Gates in an hour.

`$$f(x,\lambda) = \frac{\lambda^{x}e^{-\lambda}}{x!}$$`

Mean: `\(np\)`  
Variance: `\(np(1-p)\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-21-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---
count: false

## Probability Mass Functions

.pull-left[

&lt;br&gt;

__Poisson distribution__: distribution of a random variable whose value is equal to the number of events occurring in a fixed interval of time or space. E.g., number of orcs passing through the Black Gates in an hour.

`$$f(x,\lambda) = \frac{\lambda^{x}e^{-\lambda}}{x!}$$`

Mean: `\(np\)`  
Variance: `\(np(1-p)\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-22-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---

## Probability Density Functions

.pull-left[

&lt;br&gt;

__Normal distribution__: distribution of a continuous random variable whose distribution is symmetric from positive to negative infinity. E.g., the height of actors who auditioned for the role of Aragorn.

`$$f(x,\mu,\sigma) = \frac{1}{\sqrt{2\pi\sigma^2}}\;exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]$$`

Mean: `\(\mu\)`  
Variance: `\(\sigma^2\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-23-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---
count: false

## Probability Density Functions

.pull-left[

&lt;br&gt;

__Normal distribution__: distribution of a continuous random variable whose distribution is symmetric from positive to negative infinity. E.g., the height of actors who auditioned for the role of Aragorn.

`$$f(x,\mu,\sigma) = \frac{1}{\sqrt{2\pi\sigma^2}}\;exp\left[-\frac{1}{2}\left(\frac{x-\mu}{\sigma}\right)^2\right]$$`

Mean: `\(\mu\)`  
Variance: `\(\sigma^2\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-24-1.png" width="504" style="display: block; margin: auto;" /&gt;

]




---

## &amp;#x1F697; Cars Model

.pull-left[

Let's use the Normal distribution to describe the cars data.

- Stopping distance is a normally distributed random variable.
    - Denoted `\(Y \sim N(\mu, \sigma)\)`.
- Our experiment is a random sample of size `\(n\)` from that distribution.
    - With `\(y_1, y_2, ..., y_n\)` observations (values).
- The population _parameters_ (\\(\mu, \sigma\\)) cannot be measured directly, so we estimate them with sample _statistics_ (\\(\bar{y}, s\\)).

]



.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-25-1.png" width="504" style="display: block; margin: auto;" /&gt;


]



---

## &amp;#x1F697; Cars Model

.pull-left[

Sample statistics:

- Mean (\\(\bar{y}\\)) = 10.54 m

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-26-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---
count: false

## &amp;#x1F697; Cars Model

.pull-left[

Sample statistics:

- Mean (\\(\bar{y}\\)) = 10.54 m

This is our approximate expectation

- `\(E[y] = \mu \approx \bar{y}\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-27-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---
count: false

## &amp;#x1F697; Cars Model

.pull-left[

Sample statistics:

- Mean (\\(\bar{y}\\)) = 10.54 m

But, there's error, `\(\epsilon\)`, in this estimate.

- `\(\epsilon_i = y_i - \bar{y}\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-28-1.png" width="504" style="display: block; margin: auto;" /&gt;

]


---
count: false

## &amp;#x1F697; Cars Model

.pull-left[

Sample statistics:

- Mean (\\(\bar{y}\\)) = 10.54 m

The average squared error is the variance:

- `\(s^2 = \frac{1}{n-1}\sum \epsilon_{i}^{2}\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-29-1.png" width="504" style="display: block; margin: auto;" /&gt;

]


---
count: false

## &amp;#x1F697; Cars Model

.pull-left[

Sample statistics:

- Mean (\\(\bar{y}\\)) = 10.54 m
- S.D. (\\(s\\)) = 5.353 m

This is our uncertainty, how big we think any given error will be.  

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-30-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---
count: false

## &amp;#x1F697; Cars Model

.pull-left[

Sample statistics:

- Mean (\\(\bar{y}\\)) = 10.54 m
- S.D. (\\(s\\)) = 5.353 m

So, here is our probability model.

- `\(Y \sim N(\bar{y}, s)\)`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-31-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---
count: false

## &amp;#x1F697; Cars Model

.pull-left[

Sample statistics:

- Mean (\\(\bar{y}\\)) = 10.54 m
- S.D. (\\(s\\)) = 5.353 m

With it, we can say, for example, that the probability that a random draw from this distribution falls within one standard deviation (dashed lines) of the mean (solid line) is 68.3%.

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-32-1.png" width="504" style="display: block; margin: auto;" /&gt;

]


---

## Brief Review

.pull-left[

What do these terms mean?

- Mean is the __expected value__: 
    - `\(E[distance_i]=mean(distance)\)`
    - Known, deterministic, __predictable__
- Variance (or S.D.) is the __error__ in our expectation:
    - `\(\epsilon_i = distance_i - mean(distance)\)`
    - Unknown, stochastic, __unpredictable__

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-33-1.png" width="504" style="display: block; margin: auto;" /&gt;

]




---

## A Simple Formula

.pull-left[

This gives us a simple formula

`$$y_i = E[y] + \epsilon_i$$`

where

- `\(y_i\)` = stopping distance for car `\(i\)`, __data__
- `\(E[y]\)` = expectation, __predictable__
- `\(\epsilon_i\)` = error, __unpredictable__

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-34-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---
count: false

## A Simple Formula

.pull-left[

This gives us a simple formula

`$$y_i = E[y] + \epsilon_i$$`

If we subtract the mean, we have a model of the errors centered on zero:

`$$\epsilon_i = 0 + (y_i - E[y])$$`

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-35-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---
count: false

## A Simple Formula

.pull-left[

This gives us a simple formula

`$$y_i = E[y] + \epsilon_i$$`

If we subtract the mean, we have a model of the errors centered on zero:

`$$\epsilon_i = 0 + (y_i - E[y])$$`

Note that the
- Mean of the errors: 0
- Variance of the errors: same as before.

This means we can construct a probability model of the errors.

]

.pull-right[

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-36-1.png" width="504" style="display: block; margin: auto;" /&gt;

]



---
count: false

## A Simple Formula

&lt;img src="02-Models_and_Probability_files/figure-html/unnamed-chunk-37-1.png" width="850" style="display: block; margin: auto;" /&gt;




---
class: highlight-last-item
count: false

## A Simple Formula

Now our simple formula is this:

`$$y_i = E[y] + \epsilon_i$$` 
$$\epsilon \sim N(0, \sigma^2) $$

--
- Again, `\(E[y] = \mu \approx \bar{y}\)`. 

--
- For any future outcome:
    - The expected value is deterministic
    - The error is stochastic (random draws from a probability distribution)
--
- Must assume that the errors are _iid_!
    - **I**ndependent = the probability of one error has no effect on the probability of another.
    - **I**dentically **D**istributed = all the errors are drawn from the same probability distribution.
--
- The distribution is now a model of the errors!



---

## &amp;#x1F4C3; This Week's Assignments

- L02 - Summary statistics and statistical graphics
- H02 - Summarizing and visualizing archaeological data



---

## &amp;#x1F52D; Looking Ahead



.pull-left[

&lt;table class=" lightable-paper lightable-striped lightable-hover" style='font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; &lt;b&gt;Models and Probability&lt;/b&gt; &lt;span style="font-size: 80%; color: #9C9C9C;"&gt;(2022-01-18)&lt;/span&gt;&lt;br&gt;
&lt;div style="font-size: 80%; font-style: italic; color: #9C9C9C;"&gt;Expected value. Uncertainty. Distributions. Complexity.&lt;/div&gt; &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; &lt;b&gt;Inference&lt;/b&gt; &lt;span style="font-size: 80%; color: #9C9C9C;"&gt;(2022-01-25)&lt;/span&gt;&lt;br&gt;
&lt;div style="font-size: 80%; font-style: italic; color: #9C9C9C;"&gt;Hypothesis testing. P-value. Type I and Type II Error. T-test, ANOVA, Chi-squared.&lt;/div&gt; &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; &lt;b&gt;Linear Models 1&lt;/b&gt; &lt;span style="font-size: 80%; color: #9C9C9C;"&gt;(2022-02-01)&lt;/span&gt;&lt;br&gt;
&lt;div style="font-size: 80%; font-style: italic; color: #9C9C9C;"&gt;Covariance. Correlation. Ordinary Least Squares. Regression Assumptions.&lt;/div&gt; &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; &lt;b&gt;Linear Models 2&lt;/b&gt; &lt;span style="font-size: 80%; color: #9C9C9C;"&gt;(2022-02-08)&lt;/span&gt;&lt;br&gt;
&lt;div style="font-size: 80%; font-style: italic; color: #9C9C9C;"&gt;R-squared. ANOVA. Coefficient Standard Errors. Residuals and Diagnostic Plots.&lt;/div&gt; &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
