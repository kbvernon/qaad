{
  "hash": "7a5feb77b0b9a0fa826c9b7a8b3376bc",
  "result": {
    "markdown": "---\ntitle: \"Lecture 11: Maximum Likelihood\"  \ndate: 'Last updated: 2023-03-21'\n---\n\n\n\n\n## üìã Lecture Outline\n\n1. Limitations of OLS\n2. Likelihood\n3. Likelihood Estimation\n4. Maximum Likelihood Estimation (MLE)\n\n## Limitations of OLS\n\n:::::: {.columns}\n::::: {.column}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11-maximum-likelihood-slides_files/figure-html/unnamed-chunk-1-1.png){width=672}\n:::\n:::\n\n\n::: {style=\"color: #8b8b8b; width: 100%; text-align: center;\"}\n_This is a made-up dataset._ \n:::\n\n:::::\n::::: {.column}\n\nCan't use OLS to model counts or binary outcomes. Inflexible approach to quantifying uncertainty about these types of outcome.  \n\n<br>\n\nModel evaluation with ANOVA is restricted to subsets.  \n\n:::::\n::::::\n\n## Likelihood\n\n:::::: {.columns}\n::::: {.column}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11-maximum-likelihood-slides_files/figure-html/unnamed-chunk-2-1.png){width=672}\n:::\n:::\n\n\n:::::\n::::: {.column}\n\n__Definition:__ Probability of data, $X$, given model, $\\theta$.\n\n$$\\mathcal{L}(\\theta|X) = P(X|\\theta)$$\n\nIn English: \"The likelihood of the model given the data is equal to the probability of the data given the model.\"\n\nAnswers the __Question__: how unlikely or __strange__ is our data?\n\n:::::\n::::::\n\n## Likelihood Estimation\n\n::::::::: {.r-stack}\n:::::::: {.fragment .fade-out fragment-index=0 .mt-0}\n:::::: {.columns}\n::::: {.column}\n\n__A Simple Experiment__\n\n![](images/coins.png){width=75% fig-align=\"center\"}\n\nWe flip a coin $n = 100$ times and count the number of heads.  \n\n__Result:__ $h = 56$\n\n:::::\n::::: {.column}\n\nSuppose our model is that the coin is fair.  \n\n<br>\n\n__Question:__ What is $\\mathcal{L}(p=0.5|h=56)$?  \n\n<br>\n\nIn English: \"How _likely_ is it that the coin is fair given that heads came up 56 times?\"  \n\n<br>\n\n‚ö†Ô∏è This is the probability that heads comes up 56/100 times _assuming that the coin is fair_.\n\n:::::\n::::::\n::::::::\n\n:::::::: {.fragment .fade-in-then-out fragment-index=0 .mt-0}\n:::::: {.columns}\n::::: {.column}\n\n__A Simple Experiment__\n\n![](images/coins.png){width=75% fig-align=\"center\"}\n\nWe flip a coin $n = 100$ times and count the number of heads.  \n\n__Result:__ $h = 56$\n\n:::::\n::::: {.column}\n\nSuppose our model is that the coin is fair.  \n\n<br>\n\n__Question:__ What is $\\mathcal{L}(p=0.5|h=56)$?  \n\n<br>\n\nThis experiment is a series of Bernoulli trials, so we can use the binomial distribution to calculate $\\mathcal{L}(p|h)$. \n\n$$\\;\\;\\;\\;\\,\\mathcal{L}(p|h) = \\binom{n}{h}p^{h}(1-p)^{n-h}$$\n:::::\n::::::\n:::::::: \n\n:::::::: {.fragment .fade-in-then-out fragment-index=1 .mt-0}\n:::::: {.columns}\n::::: {.column}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11-maximum-likelihood-slides_files/figure-html/unnamed-chunk-3-1.png){width=672}\n:::\n:::\n\n\n:::::\n::::: {.column}\n\nSuppose our model is that the coin is fair.  \n\n<br>\n\n__Question:__ What is $\\mathcal{L}(p=0.5|h=56)$?  \n\n<br>\n\nThis experiment is a series of Bernoulli trials, so we can use the binomial distribution to calculate $\\mathcal{L}(p|h)$. \n\n$$\n\\begin{align}\n\\mathcal{L}(p=0.5|h=56) &= \\binom{100}{56}0.5^{56}(1-0.5)^{100-56}\\\\\\\\\n\\mathcal{L}(p=0.5|h=56) &= 0.039\n\\end{align}\n$$\n:::::\n::::::\n::::::::\n\n:::::::: {.fragment .fade-in fragment-index=2 .mt-0}\n:::::: {.columns}\n::::: {.column}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11-maximum-likelihood-slides_files/figure-html/unnamed-chunk-4-1.png){width=672}\n:::\n:::\n\n\n:::::\n\n::::: {.column}\n\nSuppose our model is that the coin is fair.  \n\n<br>\n\n__Question:__ What is $\\mathcal{L}(p=0.5|h=56)$?  \n\n<br>\nIn English: \"How _likely_ is it that the coin is fair given that heads came up 56 times?\"  \n\n<br>\n\n‚ö†Ô∏è This is the probability that heads comes up 56/100 times _assuming that the coin is fair_.\n\n:::::\n::::::\n::::::::\n:::::::::\n\n## Maximum Likelihood\n\n:::::: {.columns}\n::::: {.column}\n\n\n::: {.cell}\n::: {.cell-output-display}\n![](11-maximum-likelihood-slides_files/figure-html/unnamed-chunk-5-1.png){width=672}\n:::\n:::\n\n\n:::::\n\n::::: {.column}\n\n__Question:__ What value of $p$ maximizes $\\mathcal{L}(p|h)$?  \n\n$$\\hat{p} = max\\, \\mathcal{L}(p|h)$$  \n\nIn English: \"Given a set of models, choose the one that makes what we observe the most probable thing to observe.\"  \n\n<br>\n\nIt's a method for estimating the parameters of a model given some observed data.  \n\n:::::\n::::::\n\n## Maximum Likelihood Estimation\n\n::::::::: {.r-stack}\n:::::::: {.fragment .fade-out fragment-index=0 .mt-0}\n:::::: {.columns}\n::::: {.column}\n\nWhat if we have multiple observations?\n\n$$X = [5, 7, 8, 2, 4]$$\n\n__Question:__ What is the probability that this sample comes from a normal distribution with a mean of 5 and a variance of 2?\n\n:::::\n\n::::: {.column}\n\n\n::: {.cell layout-align=\"right\"}\n::: {.cell-output-display}\n![](11-maximum-likelihood-slides_files/figure-html/unnamed-chunk-6-1.png){fig-align='right' width=90%}\n:::\n:::\n\n\n:::::\n::::::\n::::::::\n\n:::::::: {.fragment .fade-in-then-out fragment-index=0 .mt-0}\n:::::: {.columns}\n::::: {.column}\n\nThe probability density for a given observation $x_i$ given a normal distribution is:\n\n$$N(x_i,\\mu,\\sigma) = \\frac{1}{\\sqrt{2\\pi\\sigma^2}}\\;exp\\left[-\\frac{1}{2}\\left(\\frac{x_i-\\mu}{\\sigma}\\right)^2\\right]$$\n\nFor any set of values $X$, the likelihood is the product of the individual densities:\n\n$$\\mathcal{L}(\\mu, \\sigma^2|x_i)=\\prod_{i=1}^{n} N(x_i, \\mu, \\sigma^2)$$\n:::::\n\n::::: {.column}\n\n\n::: {.cell layout-align=\"right\"}\n::: {.cell-output-display}\n![](11-maximum-likelihood-slides_files/figure-html/unnamed-chunk-7-1.png){fig-align='right' width=90%}\n:::\n:::\n\n\n:::::\n::::::\n::::::::\n\n:::::::: {.fragment .fade-in fragment-index=1 .mt-0}\n:::::: {.columns}\n::::: {.column}\n\nFor $X = [5, 7, 8, 2, 4]$, we have\n\n<br>\n\n\n::: {.cell}\n\n:::\n\n\n\n$$\n\\begin{align}\n\\mathcal{L}(\\mu, \\sigma^2|X) &= N(5) \\cdot N(7) \\cdot N(8) \\cdot N(2) \\cdot N(4)\\\\\\\\ \n&= 1.78e-05\n\\end{align}\n$$\n<br>\n\nwhere $\\mu=5$ and $\\sigma^2=2$.\n\nAs the likelihood is often very small, a common strategy is to minimize the negative log likelihood rather than maximize the likelihood, ($min\\;\\mathrm{-}\\ell$) rather than ($max\\;\\mathcal{L}$).\n\n:::::\n\n::::: {.column}\n\n\n::: {.cell layout-align=\"right\"}\n::: {.cell-output-display}\n![](11-maximum-likelihood-slides_files/figure-html/unnamed-chunk-9-1.png){fig-align='right' width=90%}\n:::\n:::\n\n\n:::::\n::::::\n::::::::\n:::::::::\n",
    "supporting": [
      "11-maximum-likelihood-slides_files"
    ],
    "filters": [
      "rmarkdown/pagebreak.lua"
    ],
    "includes": {},
    "engineDependencies": {},
    "preserve": {},
    "postProcess": true
  }
}