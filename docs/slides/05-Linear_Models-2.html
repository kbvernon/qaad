<!DOCTYPE html>
<html lang="" xml:lang="">
  <head>
    <title>Lecture 05: Linear Models 2</title>
    <meta charset="utf-8" />
    <script src="libs/header-attrs/header-attrs.js"></script>
    <link href="libs/tachyons/tachyons.min.css" rel="stylesheet" />
    <script src="libs/fabric/fabric.min.js"></script>
    <link href="libs/xaringanExtra-scribble/scribble.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-scribble/scribble.js"></script>
    <script>document.addEventListener('DOMContentLoaded', function() { window.xeScribble = new Scribble({"pen_color":["#FF0000"],"pen_size":3,"eraser_size":30,"palette":[]}) })</script>
    <link href="libs/tile-view/tile-view.css" rel="stylesheet" />
    <script src="libs/tile-view/tile-view.js"></script>
    <link href="libs/animate.css/animate.xaringan.css" rel="stylesheet" />
    <link href="libs/panelset/panelset.css" rel="stylesheet" />
    <script src="libs/panelset/panelset.js"></script>
    <script src="libs/clipboard/clipboard.min.js"></script>
    <link href="libs/shareon/shareon.min.css" rel="stylesheet" />
    <script src="libs/shareon/shareon.min.js"></script>
    <link href="libs/xaringanExtra-shareagain/shareagain.css" rel="stylesheet" />
    <script src="libs/xaringanExtra-shareagain/shareagain.js"></script>
    <script src="libs/kePrint/kePrint.js"></script>
    <link href="libs/lightable/lightable.css" rel="stylesheet" />
    <link rel="stylesheet" href="xaringan-themer.css" type="text/css" />
    <link rel="stylesheet" href="custom_style.css" type="text/css" />
  </head>
  <body>
    <textarea id="source">
class: center, middle, inverse, title-slide

# Lecture 05: Linear Models 2
### Last updated: 2022-02-07

---






## &amp;#x1F4CB; Lecture Outline

- &amp;#x1F9EA; A simple experiment
- Competing Models
- A simple formula
- ANOVA for models
- R-Squared
- t-test for coefficients
- Diagnostic plots


---

## &amp;#x1F9EA; A simple experiment

.pull-left[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-3-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;br&gt;

We take _n_ cars, send each down a track, have them brake at the same point, and measure the distance it takes them to stop.  

__Question:__ how far do you think it will take the _next_ car to stop?

]


---

## Competing Models

.pull-left[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-4-1.png" width="504" style="display: block; margin: auto;" /&gt;

.right[Expectation: mean distance &amp;nbsp;&amp;nbsp;]

]


---

## Competing Models

.pull-left[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-5-1.png" width="504" style="display: block; margin: auto;" /&gt;

.right[Expectation: mean distance &amp;nbsp;&amp;nbsp;]

]

.pull-right[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-6-1.png" width="504" style="display: block; margin: auto;" /&gt;

.right[Expectation: some function of speed &amp;nbsp;&amp;nbsp;]

]





---

## A simple formula

.pull-left[

.w-100.bg-near-white.ba.bw1.br2.shadow-4.ph3.mb3.h6rem[

`$$y_i = E(Y) + \epsilon_i$$`
`$$\epsilon \sim N(0, \sigma)$$`

]

.center[

.pull-left.bg-maize_crayola_o_50.ba.bw1.br2.shadow-4.pt4.pa3.h5[

.f4.fw6[Simple Model]

$$
`\begin{align}
E(Y) &amp;= \mu  \\\\
\bar{y} &amp;=9.663  \\\\
\sigma &amp;= 6.961 \\
\end{align}`
$$   

]

.pull-right.bg-celadon_blue_o_70.ba.bw1.br2.shadow-4.pt4.pa3.h5[.white[

.f4.fw6[Complex Model]

$$
`\begin{align}
E(Y) &amp;= \beta X \\\\ 
\hat\beta &amp;= 2.362 \\\\
\sigma &amp;= 2.667 \\
\end{align}`
$$   

]]

]

]



---
count: false

## A simple formula

.pull-left[

.w-100.bg-near-white.ba.bw1.br2.shadow-4.ph3.mb3.h6rem[

`$$y_i = E(Y) + \epsilon_i$$`
`$$\epsilon \sim N(0, \sigma)$$`

]

.center[

.pull-left.bg-maize_crayola_o_50.ba.bw1.br2.shadow-4.pt4.pa3.h5[

.f4.fw6[Simple Model]

$$
`\begin{align}
E(Y) &amp;= \mu  \\\\
\bar{y} &amp;=9.663  \\\\
\sigma &amp;= 6.961 \\
\end{align}`
$$    

]

.pull-right.bg-celadon_blue_o_70.ba.bw1.br2.shadow-4.pt4.pa3.h5[.white[

.f4.fw6[Complex Model]

$$
`\begin{align}
E(Y) &amp;= \beta X \\\\ 
\hat\beta &amp;= 2.362 \\\\
\sigma &amp;= 2.667 \\
\end{align}`
$$   

]]

]

]

.pull-right[

&amp;#x2696;&amp;#xFE0F; __The error is smaller__ for the more complex model. This is a good thing, __but what did it cost us__? Need to weigh this against the increased complexity!  

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-7-1.png" width="100%" style='margin-top: 40px;' style="display: block; margin: auto;" /&gt;

]




---

## ANOVA for model

.panelset[

.panel[.panel-name[Problem]

.pull-left[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-8-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

.pull-right[

We have two models of our data, one simple, the other complex.  

__Question:__ Does the complex (bivariate) model explain more variance than the simple (intercept) model? Does the difference arise by chance?

]

]

.panel[.panel-name[Hypotheses]

The __null__ hypothesis:
- `\(H_0:\)` no difference in variance explained.

The __alternate__ hypothesis:
- `\(H_1:\)` difference in variance explained.

]

.panel[.panel-name[Strategy]

__Variance Decomposition__. Total variance in the dependent variable can be decomposed into the variance captured by the more complex model and the remaining (or residual) variance:  

&lt;br&gt;

.pull-left[

Decompose the differences:

`$$(y_{i} - \bar{y}) = (\hat{y}_{i} - \bar{y}) + (y_{i} - \hat{y}_{i})$$`

where

- `\((y_{i} - \bar{y})\)` is the total error,  
- `\((\hat{y}_{i} - \bar{y})\)` is the model error, and
- `\((y_{i} - \hat{y}_{i})\)` is the residual error.  

]

.pull-right[

Sum and square the differences:

`$$SS_{T} = SS_{M} + SS_{R}$$`

where 

- `\(SS_{T}\)`: Total Sum of Squares
- `\(SS_{M}\)`: Model Sum of Squares
- `\(SS_{R}\)`: Residual Sum of Squares 

]

]

.panel[.panel-name[Sum of Squares]

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-9-1.png" width="1000" style="display: block; margin: auto;" /&gt;

]

.panel[.panel-name[F-statistic]



.pull-left[

Ratio of variances:

`$$F = \frac{\text{between-group variance}}{\text{within-group variance}}$$`
where

- Model variance = `\(\frac{SS_{M}}{k}\)`

- Residual variance = `\(\frac{SS_{R}}{n-k-1}\)`

Here, the denominators are the degrees of freedom, with `\(n\)` observations and `\(k\)` model parameters.

]

.pull-right[

For this test, `\(F=\)` 105.621.

__Question:__ How probable is this estimate?  

We can answer this question by comparing the F-statistic to the F-distribution. 

]

]

.panel[.panel-name[F-distribution]

.pull-left-38[

&lt;br&gt;

Summary:
- `\(\alpha = 0.05\)`
- `\(H_0:\)` no difference between groups.
- `\(p=\)` 1.036\times 10^{-8}

__Translation:__ the null hypothesis is really, really unlikely. So, there must be some difference between groups!

]

.pull-right-60[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-11-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

]

]




---

## R-Squared

.pull-left[

Coefficient of Determination

`$$R^2 = \frac{SS_{M}}{SS_{T}}$$`  

- Proportion of variance in `\(y\)` that can be explained by the model, `\(M\)`.
- Scale is 0 to 1. Closer to 1 means more variance explained.
- Model evaluation relative to a simple, intercept-only (or mean-only) model, `\(SS_T\)`.

]

.pull-right[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-12-1.png" width="430" style="display: block; margin: auto auto auto 0;" /&gt;

]



---

## t-test for coefficients

.panelset[

.panel[.panel-name[Problem]

.pull-left[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-13-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;br&gt;

__Question:__ Are the coefficient estimates significantly different than zero?

To answer this question, we need some measure of uncertainty for these estimates.

]


]

.panel[.panel-name[Hypotheses]

The __null__ hypothesis:
- `\(H_0:\)` coefficient estimate is _not_ different than zero.

The __alternate__ hypothesis:
- `\(H_1:\)` coefficient estimate is different than zero.

]

.panel[.panel-name[Standard Errors]

.pull-left[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-14-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;br&gt;

For simple linear regression,

- the __standard error of the slope__, `\(se(\hat\beta_1)\)`, is the ratio of the average squared error of the model to the total squared error of the predictor.

- the __standard error of the intercept__, `\(se(\hat\beta_0)\)`, is `\(se(\hat\beta_1)\)` weighted by the average squared values of the predictor.

]

]

.panel[.panel-name[t-statistic]



.pull-left[

The t-statistic is the coefficient estimate divided by its standard error

`$$t = \frac{\hat\beta}{se(\hat\beta)}$$` 

&lt;br&gt;

This can be compared to a t-distribution with `\(n-k-1\)` degrees of freedom (\\(n\\) observations and \\(k\\) independent predictors). 

]

]


.panel[.panel-name[t-test]



.pull-left[

&lt;br&gt;

- `\(\alpha = 0.05\)`
- `\(H_0\)`: coefficient is not different than zero
- p-values:
    - intercept = 0.002
    - slope &lt; 0.001

]

.pull-right[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-17-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

]

.panel[.panel-name[Confidence ribbon]

.pull-left[

&lt;br&gt;

The standard errors can be visualized in a graph with the regression line.

- Common to show `\(2 \cdot se(\hat\beta)\)`, as this encompasses roughly 95% of the observations.
- Notice that the errors expand as they move away from the center of the data. This reflects an increase in model uncertainty.

]

.pull-right[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-18-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

]



]


---

## Diagnostic Plots

&lt;!--- 
https://stats.stackexchange.com/questions/58141/interpreting-plot-lm
---&gt;

.panelset.sideways[

.panel[.panel-name[Regression assumptions]

1. __Weak Exogeneity__: the predictor variables have fixed values and are known. 

2. __Linearity__: the relationship between the predictor variables and the response variable is linear.  

2. __Constant Variance__: the variance of the errors does not depend on the values of the predictor variables. Also known as _homoscedasticity_.  

2. __Independence of errors__: the errors are uncorrelated with each other.  

2. __No perfect collinearity__: the predictors are not linearly correlated with each other.  

]

.panel[.panel-name[Residual v Fitted]

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-19-1.png" width="750" style="display: block; margin: auto;" /&gt;

]

.panel[.panel-name[Normal Q-Q]

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-20-1.png" width="470" style="display: block; margin: auto;" /&gt;

]

.panel[.panel-name[Cook's Distance]

.pull-left[

&lt;img src="05-Linear_Models-2_files/figure-html/unnamed-chunk-21-1.png" width="504" style="display: block; margin: auto;" /&gt;

]

.pull-right[

&lt;img src="images/fulcrum.png" width="100%" style="display: block; margin: auto auto auto 0;" /&gt;

]

]





]








---

## &amp;#x1F52D; Looking Ahead



.pull-left[

&lt;table class=" lightable-paper lightable-striped lightable-hover" style='font-family: "Arial Narrow", arial, helvetica, sans-serif; margin-left: auto; margin-right: auto;'&gt;
&lt;tbody&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; &lt;b&gt;Linear Models 2&lt;/b&gt; &lt;span style="font-size: 80%; color: #9C9C9C;"&gt;(2022-02-08)&lt;/span&gt;&lt;br&gt;
&lt;div style="font-size: 80%; font-style: italic; color: #9C9C9C;"&gt;R-squared. ANOVA. Coefficient Standard Errors. Residuals and Diagnostic Plots.&lt;/div&gt; &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; &lt;b&gt;Linear Models 3&lt;/b&gt; &lt;span style="font-size: 80%; color: #9C9C9C;"&gt;(2022-02-15)&lt;/span&gt;&lt;br&gt;
&lt;div style="font-size: 80%; font-style: italic; color: #9C9C9C;"&gt;Prediction. Interpretation. Polynomial Regression. Log-transformations. Heteroschedasticity.&lt;/div&gt; &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; &lt;b&gt;Linear Models 4&lt;/b&gt; &lt;span style="font-size: 80%; color: #9C9C9C;"&gt;(2022-02-22)&lt;/span&gt;&lt;br&gt;
&lt;div style="font-size: 80%; font-style: italic; color: #9C9C9C;"&gt;Multiple Linear Regression, Multicollinearity, Variance Inflation Factor, ANOVA&lt;/div&gt; &lt;/td&gt;
  &lt;/tr&gt;
  &lt;tr&gt;
   &lt;td style="text-align:left;"&gt; &lt;b&gt;Linear Models 5&lt;/b&gt; &lt;span style="font-size: 80%; color: #9C9C9C;"&gt;(2022-03-01)&lt;/span&gt;&lt;br&gt;
&lt;div style="font-size: 80%; font-style: italic; color: #9C9C9C;"&gt;Scaling, Dummy Variables, Interactions, ANOVA&lt;/div&gt; &lt;/td&gt;
  &lt;/tr&gt;
&lt;/tbody&gt;
&lt;/table&gt;

]
    </textarea>
<style data-target="print-only">@media screen {.remark-slide-container{display:block;}.remark-slide-scaler{box-shadow:none;}}</style>
<script src="https://remarkjs.com/downloads/remark-latest.min.js"></script>
<script>var slideshow = remark.create({
"highlightStyle": "magula",
"highlightLines": true,
"countIncrementalSlides": false,
"ratio": "16:9"
});
if (window.HTMLWidgets) slideshow.on('afterShowSlide', function (slide) {
  window.dispatchEvent(new Event('resize'));
});
(function(d) {
  var s = d.createElement("style"), r = d.querySelector(".remark-slide-scaler");
  if (!r) return;
  s.type = "text/css"; s.innerHTML = "@page {size: " + r.style.width + " " + r.style.height +"; }";
  d.head.appendChild(s);
})(document);

(function(d) {
  var el = d.getElementsByClassName("remark-slides-area");
  if (!el) return;
  var slide, slides = slideshow.getSlides(), els = el[0].children;
  for (var i = 1; i < slides.length; i++) {
    slide = slides[i];
    if (slide.properties.continued === "true" || slide.properties.count === "false") {
      els[i - 1].className += ' has-continuation';
    }
  }
  var s = d.createElement("style");
  s.type = "text/css"; s.innerHTML = "@media print { .has-continuation { display: none; } }";
  d.head.appendChild(s);
})(document);
// delete the temporary CSS (for displaying all slides initially) when the user
// starts to view slides
(function() {
  var deleted = false;
  slideshow.on('beforeShowSlide', function(slide) {
    if (deleted) return;
    var sheets = document.styleSheets, node;
    for (var i = 0; i < sheets.length; i++) {
      node = sheets[i].ownerNode;
      if (node.dataset["target"] !== "print-only") continue;
      node.parentNode.removeChild(node);
    }
    deleted = true;
  });
})();
(function() {
  "use strict"
  // Replace <script> tags in slides area to make them executable
  var scripts = document.querySelectorAll(
    '.remark-slides-area .remark-slide-container script'
  );
  if (!scripts.length) return;
  for (var i = 0; i < scripts.length; i++) {
    var s = document.createElement('script');
    var code = document.createTextNode(scripts[i].textContent);
    s.appendChild(code);
    var scriptAttrs = scripts[i].attributes;
    for (var j = 0; j < scriptAttrs.length; j++) {
      s.setAttribute(scriptAttrs[j].name, scriptAttrs[j].value);
    }
    scripts[i].parentElement.replaceChild(s, scripts[i]);
  }
})();
(function() {
  var links = document.getElementsByTagName('a');
  for (var i = 0; i < links.length; i++) {
    if (/^(https?:)?\/\//.test(links[i].getAttribute('href'))) {
      links[i].target = '_blank';
    }
  }
})();
// adds .remark-code-has-line-highlighted class to <pre> parent elements
// of code chunks containing highlighted lines with class .remark-code-line-highlighted
(function(d) {
  const hlines = d.querySelectorAll('.remark-code-line-highlighted');
  const preParents = [];
  const findPreParent = function(line, p = 0) {
    if (p > 1) return null; // traverse up no further than grandparent
    const el = line.parentElement;
    return el.tagName === "PRE" ? el : findPreParent(el, ++p);
  };

  for (let line of hlines) {
    let pre = findPreParent(line);
    if (pre && !preParents.includes(pre)) preParents.push(pre);
  }
  preParents.forEach(p => p.classList.add("remark-code-has-line-highlighted"));
})(document);</script>

<script>
slideshow._releaseMath = function(el) {
  var i, text, code, codes = el.getElementsByTagName('code');
  for (i = 0; i < codes.length;) {
    code = codes[i];
    if (code.parentNode.tagName !== 'PRE' && code.childElementCount === 0) {
      text = code.textContent;
      if (/^\\\((.|\s)+\\\)$/.test(text) || /^\\\[(.|\s)+\\\]$/.test(text) ||
          /^\$\$(.|\s)+\$\$$/.test(text) ||
          /^\\begin\{([^}]+)\}(.|\s)+\\end\{[^}]+\}$/.test(text)) {
        code.outerHTML = code.innerHTML;  // remove <code></code>
        continue;
      }
    }
    i++;
  }
};
slideshow._releaseMath(document);
</script>
<!-- dynamically load mathjax for compatibility with self-contained -->
<script>
(function () {
  var script = document.createElement('script');
  script.type = 'text/javascript';
  script.src  = 'https://mathjax.rstudio.com/latest/MathJax.js?config=TeX-MML-AM_CHTML';
  if (location.protocol !== 'file:' && /^https?:/.test(script.src))
    script.src  = script.src.replace(/^https?:/, '');
  document.getElementsByTagName('head')[0].appendChild(script);
})();
</script>
  </body>
</html>
